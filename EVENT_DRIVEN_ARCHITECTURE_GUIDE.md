# Event-Driven Architecture: Simple Guide with Diagrams

## ğŸ“š Table of Contents
1. [What is Event-Driven Architecture?](#what-is-event-driven-architecture)
2. [Simple Example: How It Works](#simple-example-how-it-works)
3. [Before vs After: Visual Comparison](#before-vs-after-visual-comparison)
4. [Kafka Basics: Key Concepts](#kafka-basics-key-concepts)
5. [Real-World Flow: Step by Step](#real-world-flow-step-by-step)
6. [Scaling: How Kafka Handles Load](#scaling-how-kafka-handles-load)
7. [Code Examples](#code-examples)
8. [Best Practices](#best-practices)

---

# Apache Kafka Overview

## What is Kafka?
Apache Kafka is a distributed event streaming platform used for building real-time data pipelines and streaming applications. It is designed for:
- High throughput
- Fault tolerance
- Scalability
- Real-time event streaming

---

## Why Kafka?
- Handles **millions of events per second**
- Highly scalable using **partitions**
- Fault-tolerant using **replication**
- Decouples microservices (event-driven architecture)

---

# Core Concepts

## 1. Topic
A category where messages (events) are stored.

## 2. Partition
A topic is divided into partitions for:
- Parallelism
- High throughput
- Ordering inside a partition
Example:  
`orders` topic â†’ `P0, P1, P2`

## 3. Producer
Sends messages to Kafka topics.

## 4. Consumer
Reads messages from topics.

## 5. Consumer Group
Multiple consumers collaborating to read a topic.
- Each partition is consumed by only **one** consumer within a group
- Ensures load balancing

## 6. Broker
A single Kafka server.

## 7. Replication
Each partition has copies across brokers for fault tolerance.

---

# Kafka Example Flow

1. Producer sends:



4. Consumers process messages in parallel.

---

# Real-World Use Cases
- Microservices communication
- Payment events
- Order-processing (e-commerce)
- Logging pipelines
- Fraud detection
- User activity tracking
- Monitoring and analytics

---

# Interview Questions (with Answers)

## 1. What is Kafka?
A distributed event streaming system for high-throughput real-time data pipelines.

## 2. What is a partition?
A unit of parallelism that stores ordered messages.  
More partitions â†’ more consumers â†’ more throughput.

## 3. What is a consumer group?
A group of consumers that share work.  
Each partition is consumed by exactly one consumer in the group.

## 4. How does Kafka achieve fault tolerance?
- Replication across brokers
- Leader-follower architecture

## 5. How does Kafka achieve ordering?
Order is guaranteed **only within a partition**, not across partitions.

## 6. Is Kafka pull-based or push-based?
Kafka is **pull-based**.

## 7. How does producer decide which partition to write to?
- By key hashing
- Round-robin (if key not provided)
- Custom partitioner

## 8. When does rebalance happen?
When:
- A consumer joins the group
- A consumer leaves
- Partitions change

## 9. What is replication factor?
Number of copies of each partition:
- RF=3 â†’ 1 leader + 2 followers

## 10. How to scale consumers?
Increase number of partitions.

---

# End of Document


## What is Event-Driven Architecture?

### Simple Explanation

**Think of it like a newspaper:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Newspaper     â”‚  â† Kafka (Event Broker)
â”‚   Publisher     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Publishes news
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Subscribers   â”‚
â”‚  (Consumers)    â”‚
â”‚                 â”‚
â”‚  ğŸ“° Person A    â”‚  â† Reads sports news
â”‚  ğŸ“° Person B    â”‚  â† Reads business news
â”‚  ğŸ“° Person C    â”‚  â† Reads all news
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**In our system:**
- **Publisher** = Order Service (creates order)
- **Newspaper** = Kafka (stores events)
- **Subscribers** = Inventory, Payment, Notification Services (react to order)

### Key Concepts

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EVENT      â”‚  = Something that happened
â”‚              â”‚    Example: "Order #123 created"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PRODUCER   â”‚  = Service that creates events
â”‚              â”‚    Example: Order Service
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Sends event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KAFKA      â”‚  = Message broker (like a mailbox)
â”‚   (Broker)   â”‚    Stores events temporarily
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Delivers event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CONSUMER   â”‚  = Service that reacts to events
â”‚              â”‚    Example: Inventory Service
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Simple Example: How It Works

### Scenario: User Places an Order

```
Step 1: User clicks "Buy Now"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Order Service     â”‚
â”‚                     â”‚
â”‚  1. Save order      â”‚
â”‚  2. Send event      â”‚  â† "Order #123 created!"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ Event: OrderCreated
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      KAFKA          â”‚
â”‚   Topic: orders     â”‚  â† Stores the event
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ Broadcasts to all subscribers
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼          â–¼          â–¼          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Inventoryâ”‚ â”‚Payment â”‚ â”‚Email   â”‚ â”‚Analyticsâ”‚
   â”‚Service â”‚ â”‚Service â”‚ â”‚Service â”‚ â”‚Service â”‚
   â”‚        â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚
   â”‚Reserve â”‚ â”‚Charge  â”‚ â”‚Send    â”‚ â”‚Track   â”‚
   â”‚Stock   â”‚ â”‚Card    â”‚ â”‚Email   â”‚ â”‚Sale    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Point:** Order Service doesn't wait! It sends the event and responds immediately to the user.

---

## Before vs After: Visual Comparison

### âŒ OLD WAY: Direct Service Calls (Synchronous)

```
User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Order Serviceâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â”€â”€â†’ Inventory Service (wait 100ms) â³
    â”‚
    â”œâ”€â”€â”€â†’ Payment Service (wait 200ms) â³
    â”‚
    â”œâ”€â”€â”€â†’ Email Service (wait 50ms) â³
    â”‚
    â””â”€â”€â”€â†’ Analytics Service (wait 30ms) â³
    
Total Time: 380ms â±ï¸
User waits: 380ms ğŸ˜
```

**Problems:**
- Slow (waits for all services)
- If one service fails, everything fails
- Hard to add new services

### âœ… NEW WAY: Event-Driven (Asynchronous)

```
User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Order Serviceâ”‚
â”‚              â”‚
â”‚ 1. Save orderâ”‚
â”‚ 2. Send eventâ”‚  â† Takes only 5ms!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Event sent
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    KAFKA     â”‚  â† Stores event
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ (Services process in background)
    â”œâ”€â”€â”€â†’ Inventory Service (processes async)
    â”œâ”€â”€â”€â†’ Payment Service (processes async)
    â”œâ”€â”€â”€â†’ Email Service (processes async)
    â””â”€â”€â”€â†’ Analytics Service (processes async)
    
Total Time: 5ms âš¡
User waits: 5ms ğŸ˜Š
```

**Benefits:**
- Fast (responds immediately)
- If one service fails, others still work
- Easy to add new services

---

## Kafka Basics: Key Concepts

### 1. Topic = Category of Events

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA BROKER                â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Topic: order-created       â”‚  â”‚
â”‚  â”‚   (Like a folder)            â”‚  â”‚
â”‚  â”‚                              â”‚  â”‚
â”‚  â”‚  [Event1] [Event2] [Event3] â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Topic: payment-processed   â”‚  â”‚
â”‚  â”‚                              â”‚  â”‚
â”‚  â”‚  [Event1] [Event2]           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Partition = Sub-folder for Parallel Processing

```
Topic: order-created
â”‚
â”œâ”€â”€â”€ Partition 0 â”€â”€â”€â”€â”
â”‚    [Order1]        â”‚
â”‚    [Order4]        â”‚  â† Consumer 1 processes these
â”‚    [Order7]        â”‚
â”‚                    â”‚
â”œâ”€â”€â”€ Partition 1 â”€â”€â”€â”€â”¤
â”‚    [Order2]        â”‚
â”‚    [Order5]        â”‚  â† Consumer 2 processes these
â”‚    [Order8]        â”‚
â”‚                    â”‚
â””â”€â”€â”€ Partition 2 â”€â”€â”€â”€â”˜
     [Order3]        â”‚
     [Order6]        â”‚  â† Consumer 3 processes these
     [Order9]        â”‚
```

**Why Partitions?**
- Allows multiple consumers to work in parallel
- 3 partitions = 3 consumers can work simultaneously
- Faster processing!

### 3. Consumer Group = Team of Workers

```
Consumer Group: inventory-service-group
â”‚
â”œâ”€â”€â”€ Consumer 1 (Server 1) â”€â”€â”€â”€â†’ Partition 0
â”‚
â”œâ”€â”€â”€ Consumer 2 (Server 2) â”€â”€â”€â”€â†’ Partition 1
â”‚
â””â”€â”€â”€ Consumer 3 (Server 3) â”€â”€â”€â”€â†’ Partition 2

All working in parallel! ğŸš€
```

**Visual Example:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      KAFKA: order-created Topic         â”‚
â”‚                                          â”‚
â”‚  P0: [O1] [O4] [O7]  â†â”€â”€ Consumer 1    â”‚
â”‚  P1: [O2] [O5] [O8]  â†â”€â”€ Consumer 2    â”‚
â”‚  P2: [O3] [O6] [O9]  â†â”€â”€ Consumer 3    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Real-World Flow: Step by Step

### âš ï¸ Important: Payment Confirmation Flow

**Question:** Without payment confirmation, how will order be processed?

**Answer:** We need to wait for payment confirmation before processing the order! Here's the correct flow:

### Complete Order Flow with Payment Confirmation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 1: User Places Order                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ‘¤ User clicks "Place Order"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 2: Order Created (PENDING)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Order Service      â”‚
â”‚                      â”‚
â”‚  1. âœ… Save to DB    â”‚
â”‚     Status: PENDING  â”‚
â”‚  2. ğŸ“¤ Send Event    â”‚  â† "Order #123 created!"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Event: order-created
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA BROKER                 â”‚
â”‚                                      â”‚
â”‚  Topic: order-created                â”‚
â”‚  [Order #123 - Status: PENDING]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Only Payment Service reacts!
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 3: Payment Processing                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Payment Service    â”‚
â”‚                      â”‚
â”‚  1. ğŸ’³ Charge Card   â”‚
â”‚  2. âœ… Payment OK    â”‚
â”‚  3. ğŸ“¤ Send Event    â”‚  â† "Payment confirmed!"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Event: payment-confirmed
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA BROKER                 â”‚
â”‚                                      â”‚
â”‚  Topic: payment-confirmed            â”‚
â”‚  [Order #123 - Payment: SUCCESS]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ NOW other services can process!
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        STEP 4: Order Processing (After Payment)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inventory   â”‚  â”‚   Shipping   â”‚  â”‚ Notification â”‚  â”‚  Analytics   â”‚
â”‚   Service    â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ âœ… Reserve   â”‚  â”‚ âœ… Prepare   â”‚  â”‚ âœ… Send      â”‚  â”‚ âœ… Track     â”‚
â”‚    Stock     â”‚  â”‚    Shipment  â”‚  â”‚    Email     â”‚  â”‚    Sale      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Order States Flow

```
Order Status Flow:

PENDING â”€â”€â†’ (Payment Processing) â”€â”€â†’ PAID â”€â”€â†’ (Processing) â”€â”€â†’ SHIPPED â”€â”€â†’ DELIVERED
   â”‚              â”‚                    â”‚            â”‚              â”‚
   â”‚              â”‚                    â”‚            â”‚              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    If payment fails
                         â”‚
                         â–¼
                    CANCELLED
```

### Visual Timeline with Payment

```
Time â†’
â”‚
â”œâ”€ 0ms:   User clicks "Place Order"
â”‚
â”œâ”€ 10ms:  Order saved (Status: PENDING)
â”‚
â”œâ”€ 15ms:  Event: order-created sent
â”‚
â”œâ”€ 20ms:  âœ… Response to user: "Order placed, processing payment..."
â”‚
â”‚         (Background: Payment processing)
â”‚
â”œâ”€ 50ms:  Payment Service: Charging card...
â”‚
â”œâ”€ 200ms: Payment Service: âœ… Payment successful!
â”‚
â”œâ”€ 205ms: Event: payment-confirmed sent
â”‚
â”‚         (NOW other services can process)
â”‚
â”œâ”€ 250ms: Inventory Service: âœ… Stock reserved
â”‚
â”œâ”€ 300ms: Shipping Service: âœ… Shipment prepared
â”‚
â”œâ”€ 350ms: Email Service: âœ… Confirmation sent
â”‚
â””â”€ 400ms: Analytics Service: âœ… Sale tracked
```

**Key Point:** User gets response in 20ms, but order processing only starts AFTER payment confirmation!

### Payment-First Flow (Correct Approach)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CORRECT FLOW: Payment First                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Order Created Event
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Payment Service     â”‚  â† Only this reacts first!
â”‚                      â”‚
â”‚  Processes payment   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â†’ Payment Success â”€â”€â†’ Payment Confirmed Event
    â”‚                           â”‚
    â”‚                           â–¼
    â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚  Other Services      â”‚
    â”‚                   â”‚  (Inventory, etc.)   â”‚
    â”‚                   â”‚  NOW can process!    â”‚
    â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â†’ Payment Failed â”€â”€â†’ Order Cancelled Event
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Release resources   â”‚
                        â”‚  Notify user         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Scaling: How Kafka Handles Load

### âš ï¸ Important: How Multiple Service Instances Work

**Question:** If I have 3 instances of Inventory Service running, how does Kafka ensure each event is consumed by only ONE instance?

**Answer:** Kafka uses **Consumer Groups** and **Partition Assignment** to ensure exactly one consumer per partition!

### Consumer Groups: The Key Concept

```
Consumer Group = Team of workers from the same service

Rule: Each partition can be consumed by ONLY ONE consumer in a group
```

### Visual: Multiple Service Instances

#### Scenario: 3 Instances of Inventory Service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KAFKA: order-created Topic                 â”‚
â”‚                                                         â”‚
â”‚  Partition 0: [O1] [O4] [O7] [O10] ...                â”‚
â”‚  Partition 1: [O2] [O5] [O8] [O11] ...                â”‚
â”‚  Partition 2: [O3] [O6] [O9] [O12] ...                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ Consumer Group: inventory-service-group
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Instance 1 â”‚ â”‚  Instance 2 â”‚ â”‚  Instance 3 â”‚
â”‚  (Server 1) â”‚ â”‚  (Server 2) â”‚ â”‚  (Server 3) â”‚
â”‚             â”‚ â”‚             â”‚ â”‚             â”‚
â”‚  Consumer 1 â”‚ â”‚  Consumer 2 â”‚ â”‚  Consumer 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚               â”‚
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
   Partition 0     Partition 1     Partition 2
   
âœ… Each partition consumed by ONLY ONE instance!
âœ… No duplicate processing!
```

### How Kafka Assigns Partitions

```
Step 1: All instances join the same Consumer Group
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Consumer Group: inventory-group    â”‚
â”‚                                     â”‚
â”‚  Instance 1 (Consumer 1)            â”‚
â”‚  Instance 2 (Consumer 2)            â”‚
â”‚  Instance 3 (Consumer 3)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
        â–¼
Step 2: Kafka automatically assigns partitions
        â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Partition Assignment:              â”‚
â”‚                                     â”‚
â”‚  Consumer 1 â†’ Partition 0           â”‚
â”‚  Consumer 2 â†’ Partition 1           â”‚
â”‚  Consumer 3 â†’ Partition 2           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
        â–¼
Step 3: Each consumer processes ONLY its assigned partition
```

### Detailed Example: 3 Instances, 3 Partitions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAFKA TOPIC                          â”‚
â”‚              Topic: order-created                       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Partition 0  â”‚  â”‚ Partition 1  â”‚  â”‚ Partition 2  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ [Order #1]   â”‚  â”‚ [Order #2]   â”‚  â”‚ [Order #3]   â”‚ â”‚
â”‚  â”‚ [Order #4]   â”‚  â”‚ [Order #5]   â”‚  â”‚ [Order #6]   â”‚ â”‚
â”‚  â”‚ [Order #7]   â”‚  â”‚ [Order #8]   â”‚  â”‚ [Order #9]   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ Consumer Group: inventory-service-group
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INVENTORY SERVICE INSTANCES                â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Instance 1  â”‚  â”‚  Instance 2  â”‚  â”‚  Instance 3  â”‚ â”‚
â”‚  â”‚  (Server 1)  â”‚  â”‚  (Server 2)  â”‚  â”‚  (Server 3)  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Consumer 1   â”‚  â”‚ Consumer 2   â”‚  â”‚ Consumer 3   â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Reads from   â”‚  â”‚ Reads from   â”‚  â”‚ Reads from   â”‚ â”‚
â”‚  â”‚ Partition 0  â”‚  â”‚ Partition 1  â”‚  â”‚ Partition 2  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Processes:   â”‚  â”‚ Processes:   â”‚  â”‚ Processes:   â”‚ â”‚
â”‚  â”‚ Order #1     â”‚  â”‚ Order #2     â”‚  â”‚ Order #3     â”‚ â”‚
â”‚  â”‚ Order #4     â”‚  â”‚ Order #5     â”‚  â”‚ Order #6     â”‚ â”‚
â”‚  â”‚ Order #7     â”‚  â”‚ Order #8     â”‚  â”‚ Order #9     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Order #1 processed ONLY by Instance 1
âœ… Order #2 processed ONLY by Instance 2
âœ… Order #3 processed ONLY by Instance 3
âœ… NO duplicate processing!
```

### What Happens When You Add/Remove Instances?

#### Scenario 1: Add 4th Instance (More instances than partitions)

```
Before: 3 Instances, 3 Partitions
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚  I1  â”‚  â”‚  I2  â”‚  â”‚  I3  â”‚
â”‚  P0  â”‚  â”‚  P1  â”‚  â”‚  P2  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜

After: 4 Instances, 3 Partitions
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚  I1  â”‚  â”‚  I2  â”‚  â”‚  I3  â”‚  â”‚  I4  â”‚
â”‚  P0  â”‚  â”‚  P1  â”‚  â”‚  P2  â”‚  â”‚ IDLE â”‚  â† Instance 4 is idle
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜

âš ï¸  Instance 4 waits as backup (standby)
âœ… If Instance 1, 2, or 3 fails, Instance 4 takes over
```

#### Scenario 2: Remove 1 Instance (Rebalancing)

```
Before: 3 Instances, 3 Partitions
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚  I1  â”‚  â”‚  I2  â”‚  â”‚  I3  â”‚
â”‚  P0  â”‚  â”‚  P1  â”‚  â”‚  P2  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Instance 2 crashes!
    â–¼
After: 2 Instances, 3 Partitions (Kafka Rebalances)
â”Œâ”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚  I1  â”‚              â”‚  I3  â”‚
â”‚  P0  â”‚              â”‚  P2  â”‚
â”‚  P1  â”‚  â† Takes overâ”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”˜

âœ… Instance 1 now handles Partition 0 AND Partition 1
âœ… Automatic rebalancing - no manual intervention!
```

### Consumer Group Configuration

```java
// All instances use the SAME group-id
@KafkaListener(
    topics = "order-created", 
    groupId = "inventory-service-group"  // â† Same for all instances!
)
public void handleOrder(OrderCreatedEvent event) {
    // This method runs on only ONE instance per event
    inventoryService.reserve(event.getItems());
}
```

**Key Point:** All instances of the same service MUST use the same `groupId`!

### Visual: How Kafka Ensures No Duplicates

```
Event Flow:

1. Order #123 arrives in Partition 0
        â”‚
        â–¼
2. Kafka checks: Who is assigned to Partition 0?
        â”‚
        â–¼
3. Only Consumer 1 (Instance 1) is assigned
        â”‚
        â–¼
4. Kafka delivers event ONLY to Consumer 1
        â”‚
        â–¼
5. Instance 1 processes the event
        â”‚
        â–¼
6. âœ… Event processed exactly ONCE

Instance 2 and Instance 3 never see this event!
```

### Scenario: Black Friday - 10,000 orders/second

#### Without Scaling (1 Consumer)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      KAFKA: order-created           â”‚
â”‚                                     â”‚
â”‚  P0: [O1][O2][O3]...[O1000]        â”‚
â”‚  P1: [O1][O2][O3]...[O1000]        â”‚  â† All processed by
â”‚  P2: [O1][O2][O3]...[O1000]        â”‚    ONE consumer
â”‚                                     â”‚
â”‚  âš ï¸  Consumer 1 (overloaded!)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Can only process 1,000/sec
     â–¼
ğŸ˜ Slow! Queue building up!
```

#### With Scaling (3 Consumers)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      KAFKA: order-created           â”‚
â”‚                                     â”‚
â”‚  P0: [O1][O4][O7]...  â† Consumer 1 â”‚
â”‚  P1: [O2][O5][O8]...  â† Consumer 2 â”‚  â† Each handles
â”‚  P2: [O3][O6][O9]...  â† Consumer 3 â”‚    one partition
â”‚                                     â”‚
â”‚  âœ… All consumers working!          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Can process 3,000/sec (3x faster!)
     â–¼
ğŸ˜Š Fast! No queue!
```

### Key Rules

```
âœ… Rule 1: One partition = One consumer (in same group)
âœ… Rule 2: Same groupId = Same team (work together)
âœ… Rule 3: Different groupId = Different teams (all get events)
âœ… Rule 4: Kafka automatically assigns partitions
âœ… Rule 5: If consumer dies, Kafka reassigns its partition
```

### Example: Multiple Services (Different Groups)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      KAFKA: order-created           â”‚
â”‚                                     â”‚
â”‚  P0: [O1] [O4] [O7]                â”‚
â”‚  P1: [O2] [O5] [O8]                â”‚
â”‚  P2: [O3] [O6] [O9]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
        â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Group:       â”‚  â”‚ Group:       â”‚  â”‚ Group:       â”‚
â”‚ inventory    â”‚  â”‚ payment      â”‚  â”‚ email        â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Instance 1   â”‚  â”‚ Instance 1   â”‚  â”‚ Instance 1   â”‚
â”‚ Instance 2   â”‚  â”‚ Instance 2   â”‚  â”‚ Instance 2   â”‚
â”‚ Instance 3   â”‚  â”‚ Instance 3   â”‚  â”‚ Instance 3   â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Each gets    â”‚  â”‚ Each gets    â”‚  â”‚ Each gets    â”‚
â”‚ ONE partitionâ”‚  â”‚ ONE partitionâ”‚  â”‚ ONE partitionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Each service group gets ALL events
âœ… Within each group, events distributed across instances
âœ… No duplicate processing within a group
```

---

## Code Examples

### 1. Publishing an Event (Producer)

```java
@Service
public class OrderService {
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public Order createOrder(OrderRequest request) {
        // 1. Save order to database
        Order order = orderRepository.save(new Order(request));
        
        // 2. Create event
        OrderCreatedEvent event = new OrderCreatedEvent(
        order.getId(),
        order.getBuyerId(),
        order.getItems(),
            order.getTotalAmount()
        );
        
        // 3. Send to Kafka (non-blocking, fast!)
        kafkaTemplate.send("order-created", order.getId(), event);
        
        // 4. Return immediately (user doesn't wait)
        return order;
    }
}
```

**Visual Flow:**
```
createOrder()
    â”‚
    â”œâ”€â†’ Save to DB
    â”‚
    â”œâ”€â†’ Create Event
    â”‚
    â””â”€â†’ Send to Kafka â”€â”€â†’ Returns immediately âœ…
```

### 2. Consuming an Event (Consumer)

```java
@Service
public class InventoryService {
    
    // All instances of Inventory Service use SAME groupId
    @KafkaListener(topics = "order-created", groupId = "inventory-group")
    public void handleOrderCreated(OrderCreatedEvent event) {
        // This runs automatically when event arrives
        // BUT only on ONE instance (the one assigned to this partition)
        System.out.println("Processing order: " + event.getOrderId() + 
                          " on instance: " + getInstanceId());
        
        // Reserve inventory
        for (OrderItem item : event.getItems()) {
            inventoryRepository.reserve(item.getProductId(), item.getQuantity());
        }
    }
}
```

**Visual Flow:**
```
Kafka receives event in Partition 0
    â”‚
    â–¼
Kafka checks: Who is assigned to Partition 0?
    â”‚
    â–¼
Only Consumer 1 (Instance 1) is assigned
    â”‚
    â–¼
@KafkaListener on Instance 1 detects event
    â”‚
    â–¼
handleOrderCreated() runs on Instance 1 ONLY
    â”‚
    â–¼
Inventory reserved âœ…

Instance 2 and Instance 3 never see this event!
```

### 3. Payment-First Pattern (Correct Implementation)

```java
// Step 1: Order Created - Only Payment Service reacts
@KafkaListener(topics = "order-created", groupId = "payment-group")
public void processPayment(OrderCreatedEvent event) {
    // Process payment
    PaymentResult result = paymentService.charge(
        event.getOrderId(), 
        event.getTotalAmount()
    );
    
    if (result.isSuccess()) {
        // Publish payment confirmed event
        PaymentConfirmedEvent confirmedEvent = new PaymentConfirmedEvent(
            event.getOrderId(),
            event.getBuyerId(),
            event.getItems(),
            result.getTransactionId()
        );
        kafkaTemplate.send("payment-confirmed", event.getOrderId(), confirmedEvent);
    } else {
        // Publish payment failed event
        PaymentFailedEvent failedEvent = new PaymentFailedEvent(
            event.getOrderId(),
            result.getFailureReason()
        );
        kafkaTemplate.send("payment-failed", event.getOrderId(), failedEvent);
    }
}

// Step 2: Payment Confirmed - Other services can now process
@KafkaListener(topics = "payment-confirmed", groupId = "inventory-group")
public void reserveInventory(PaymentConfirmedEvent event) {
    // Only reserve inventory AFTER payment confirmed
    inventoryService.reserve(event.getOrderId(), event.getItems());
}

@KafkaListener(topics = "payment-confirmed", groupId = "shipping-group")
public void prepareShipment(PaymentConfirmedEvent event) {
    // Only prepare shipment AFTER payment confirmed
    shippingService.prepareShipment(event.getOrderId(), event.getItems());
}

@KafkaListener(topics = "payment-confirmed", groupId = "email-group")
public void sendConfirmation(PaymentConfirmedEvent event) {
    // Send confirmation email AFTER payment confirmed
    emailService.sendOrderConfirmation(event.getBuyerId(), event.getOrderId());
}

// Step 3: Handle Payment Failure
@KafkaListener(topics = "payment-failed", groupId = "order-group")
public void handlePaymentFailure(PaymentFailedEvent event) {
    // Update order status to CANCELLED
    orderService.cancelOrder(event.getOrderId(), "Payment failed");
    
    // Notify user
    notificationService.notifyPaymentFailure(event.getOrderId());
}
```

**Visual Flow:**
```
Order Created Event
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Payment Service â”‚  â† Only this reacts first!
â”‚                 â”‚
â”‚ Charge card     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â†’ Success â”€â”€â†’ Payment Confirmed Event
    â”‚                   â”‚
    â”‚                   â”œâ”€â†’ Inventory Service
    â”‚                   â”œâ”€â†’ Shipping Service
    â”‚                   â”œâ”€â†’ Email Service
    â”‚                   â””â”€â†’ Analytics Service
    â”‚
    â””â”€â†’ Failed â”€â”€â†’ Payment Failed Event
                        â”‚
                        â””â”€â†’ Order Service (Cancel order)
```

### 4. Order State Management

```java
@Service
public class OrderService {
    
    @KafkaListener(topics = "order-created", groupId = "order-group")
    public void handleOrderCreated(OrderCreatedEvent event) {
        // Update order status to PENDING
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.PENDING);
        orderRepository.save(order);
    }
    
    @KafkaListener(topics = "payment-confirmed", groupId = "order-group")
    public void handlePaymentConfirmed(PaymentConfirmedEvent event) {
        // Update order status to PAID
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.PAID);
        order.setPaymentTransactionId(event.getTransactionId());
        orderRepository.save(order);
    }
    
    @KafkaListener(topics = "payment-failed", groupId = "order-group")
    public void handlePaymentFailed(PaymentFailedEvent event) {
        // Update order status to CANCELLED
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.CANCELLED);
        order.setCancellationReason(event.getFailureReason());
        orderRepository.save(order);
    }
}
```

**State Flow Diagram:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PENDING â”‚  â† Order created, waiting for payment
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â†’ Payment Success â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       â”‚  PAID   â”‚  â† Payment confirmed
    â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                           â”‚
    â”‚                           â”œâ”€â†’ Inventory reserved
    â”‚                           â”œâ”€â†’ Shipment prepared
    â”‚                           â””â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                               â”‚ SHIPPED  â”‚
    â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â†’ Payment Failed â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ CANCELLED  â”‚  â† Order cancelled
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Payment Confirmation Pattern

### Why This Pattern?

**Problem:** We can't process orders without payment confirmation!

**Solution:** Use event chaining - wait for payment confirmation before processing.

### Event Chain Flow

```
Event 1: order-created
    â”‚
    â–¼
Payment Service processes payment
    â”‚
    â”œâ”€â†’ Success â”€â”€â†’ Event 2: payment-confirmed
    â”‚                   â”‚
    â”‚                   â””â”€â†’ Triggers: Inventory, Shipping, Email
    â”‚
    â””â”€â†’ Failed â”€â”€â†’ Event 2: payment-failed
                        â”‚
                        â””â”€â†’ Triggers: Order cancellation
```

### Implementation Pattern

```java
// Pattern: Event Chaining with State Check
    
// 1. Order Created - Start payment
    @KafkaListener(topics = "order-created")
public void initiatePayment(OrderCreatedEvent event) {
    paymentService.process(event);
}

// 2. Payment Confirmed - Process order
@KafkaListener(topics = "payment-confirmed")
public void processOrder(PaymentConfirmedEvent event) {
    // Now safe to process - payment is confirmed!
    inventoryService.reserve(event.getOrderId(), event.getItems());
    shippingService.prepare(event.getOrderId());
}

// 3. Payment Failed - Cancel order
@KafkaListener(topics = "payment-failed")
public void cancelOrder(PaymentFailedEvent event) {
    orderService.cancel(event.getOrderId());
}
```

### Safety Check Pattern

```java
@KafkaListener(topics = "payment-confirmed", groupId = "inventory-group")
public void reserveInventory(PaymentConfirmedEvent event) {
    // Double-check: Verify order is actually paid
    Order order = orderRepository.findById(event.getOrderId());
    
    if (order.getStatus() != OrderStatus.PAID) {
        logger.warn("Order {} not paid, skipping inventory reservation", 
                   event.getOrderId());
        return; // Don't process if not paid
    }
    
    // Safe to reserve inventory
    inventoryService.reserve(event.getOrderId(), event.getItems());
}
```

---

## Dead Letter Queue (DLQ) - Handling Failed Messages

### What is Dead Letter Queue?

**Problem:** Some messages fail to process (database errors, invalid data, etc.)

**Solution:** Send failed messages to a separate topic (DLQ) for manual investigation.

### Visual Flow

```
Normal Flow:
Event arrives â†’ Process â†’ Success âœ…

Failed Flow:
Event arrives â†’ Process â†’ Error âŒ â†’ Send to DLQ â†’ Manual investigation
```

### Implementation

```java
@Service
public class OrderEventConsumer {
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @KafkaListener(topics = "order-created", groupId = "inventory-group")
    public void handleOrderCreated(OrderCreatedEvent event) {
        try {
            // Try to process
            inventoryService.reserve(event.getOrderId(), event.getItems());
            
        } catch (Exception e) {
            // Log error
            logger.error("Failed to process order: {}", event.getOrderId(), e);
            
            // Send to Dead Letter Queue
            DeadLetterEvent dlqEvent = new DeadLetterEvent(
                event.getOrderId(),
                event,
                e.getMessage(),
                LocalDateTime.now()
            );
            
            kafkaTemplate.send("order-created-dlq", event.getOrderId(), dlqEvent);
        }
    }
}
```

### DLQ Consumer for Manual Review

```java
@Service
public class DeadLetterQueueHandler {
    
    @KafkaListener(topics = "order-created-dlq", groupId = "dlq-handler-group")
    public void handleDeadLetter(DeadLetterEvent dlqEvent) {
        // Store in database for manual review
        dlqRepository.save(new DeadLetterRecord(
            dlqEvent.getOriginalEvent(),
            dlqEvent.getErrorMessage(),
            dlqEvent.getTimestamp()
        ));
        
        // Send alert to operations team
        alertService.sendAlert("Failed event in DLQ: " + dlqEvent.getOrderId());
    }
}
```

### Retry Pattern with DLQ

```java
@KafkaListener(topics = "order-created", groupId = "inventory-group")
public void handleOrderCreated(OrderCreatedEvent event) {
    int maxRetries = 3;
    int retryCount = 0;
    
    while (retryCount < maxRetries) {
        try {
            inventoryService.reserve(event.getOrderId(), event.getItems());
            return; // Success!
            
        } catch (Exception e) {
            retryCount++;
            
            if (retryCount >= maxRetries) {
                // Max retries reached, send to DLQ
                logger.error("Max retries reached for order: {}", event.getOrderId());
                sendToDLQ(event, e);
            } else {
                // Wait and retry
                Thread.sleep(1000 * retryCount); // Exponential backoff
                logger.warn("Retrying order: {} (attempt {})", event.getOrderId(), retryCount);
            }
        }
    }
}
```

### DLQ Structure

```
Topics:
â”œâ”€â”€ order-created (main topic)
â”œâ”€â”€ order-created-dlq (dead letter queue)
â””â”€â”€ order-created-retry (retry topic - optional)

Flow:
order-created â†’ Process fails â†’ Retry 3 times â†’ Still fails â†’ order-created-dlq
```

### Monitoring DLQ

```java
@Service
public class DLQMonitor {
    
    @Scheduled(fixedRate = 60000) // Check every minute
    public void monitorDLQ() {
        long dlqCount = dlqRepository.countUnprocessed();
        
        if (dlqCount > 100) {
            alertService.sendAlert("DLQ has " + dlqCount + " unprocessed messages!");
        }
    }
}
```

---

## Message Memory and Retention

### How Kafka Stores Messages

```
Kafka stores messages on disk, not just in memory!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA BROKER                â”‚
â”‚                                     â”‚
â”‚  Topic: order-created               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Partition 0                   â”‚  â”‚
â”‚  â”‚                               â”‚  â”‚
â”‚  â”‚ [Message 1] â† Offset 0        â”‚  â”‚
â”‚  â”‚ [Message 2] â† Offset 1        â”‚  â”‚
â”‚  â”‚ [Message 3] â† Offset 2        â”‚  â”‚
â”‚  â”‚ ...                           â”‚  â”‚
â”‚  â”‚ [Message N] â† Offset N        â”‚  â”‚
â”‚  â”‚                               â”‚  â”‚
â”‚  â”‚ Stored on DISK (persistent)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Message Retention Policies

Kafka keeps messages based on two policies:

#### 1. Time-Based Retention

```yaml
# Keep messages for 7 days
retention.ms: 604800000  # 7 days in milliseconds
```

**Visual:**
```
Messages older than 7 days are automatically deleted

Day 1: [M1] [M2] [M3] ... [M1000]
Day 2: [M1] [M2] [M3] ... [M2000]
...
Day 7: [M1] [M2] [M3] ... [M7000]
Day 8: [M1] deleted (too old) [M2] [M3] ... [M8000]
```

#### 2. Size-Based Retention

```yaml
# Keep maximum 10GB of messages per partition
retention.bytes: 10737418240  # 10GB in bytes
```

**Visual:**
```
When partition reaches 10GB, oldest messages are deleted

[Old Messages] [New Messages]
     â†“              â†“
  Deleted      Kept (within limit)
```

### Configuration Example

```yaml
# application.yaml or server.properties
spring:
  kafka:
    consumer:
      # Consumer settings
      max-poll-records: 500  # Max messages per poll
      fetch-min-size: 1MB    # Wait for 1MB before returning
      fetch-max-wait: 500ms  # Max wait time

# Kafka server configuration (server.properties)
log.retention.hours=168        # 7 days
log.retention.bytes=10737418240 # 10GB per partition
log.segment.bytes=1073741824   # 1GB per segment
```

### Memory Usage

```
Kafka Memory Usage:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA MEMORY                â”‚
â”‚                                     â”‚
â”‚  1. Page Cache (OS Level)           â”‚
â”‚     - Recently accessed messages    â”‚
â”‚     - Fast read access              â”‚
â”‚                                     â”‚
â”‚  2. Producer Buffer                 â”‚
â”‚     - Messages waiting to send      â”‚
â”‚     - batch.size: 16KB              â”‚
â”‚                                     â”‚
â”‚  3. Consumer Buffer                 â”‚
â”‚     - Messages fetched but not      â”‚
â”‚       processed yet                 â”‚
â”‚     - fetch.min.bytes: 1MB          â”‚
â”‚                                     â”‚
â”‚  4. Index Files                     â”‚
â”‚     - Offset indexes                â”‚
â”‚     - Time indexes                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Best Practices for Memory

```java
// 1. Batch Processing (Reduces memory per message)
@KafkaListener(topics = "order-created", groupId = "inventory-group")
public void handleOrders(List<OrderCreatedEvent> events) {
    // Process multiple events at once
    inventoryService.batchReserve(events);
}

// 2. Limit Batch Size
@KafkaListener(
    topics = "order-created",
    groupId = "inventory-group",
    containerFactory = "batchKafkaListenerContainerFactory"
)
public void handleOrders(List<OrderCreatedEvent> events) {
    // Process in batches
}

// Configuration
@Bean
public ConsumerFactory<String, Object> consumerFactory() {
    Map<String, Object> props = new HashMap<>();
    props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100); // Max 100 per poll
    props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 1024 * 1024); // 1MB
    return new DefaultKafkaConsumerFactory<>(props);
}
```

### Monitoring Memory Usage

```java
@Service
public class KafkaMemoryMonitor {
    
    @Autowired
    private MeterRegistry meterRegistry;
    
    @Scheduled(fixedRate = 60000)
    public void monitorMemory() {
        // Monitor consumer lag
        long lag = getConsumerLag();
        meterRegistry.gauge("kafka.consumer.lag", lag);
        
        // Monitor partition size
        long partitionSize = getPartitionSize("order-created", 0);
        meterRegistry.gauge("kafka.partition.size", partitionSize);
        
        // Alert if lag is too high
        if (lag > 10000) {
            alertService.sendAlert("High consumer lag: " + lag);
        }
    }
}
```

---

## Monitoring Kafka

### Key Metrics to Monitor

#### 1. Consumer Lag

**What it is:** How far behind consumers are from producers

```
Producer writes: [M1] [M2] [M3] [M4] [M5] [M6] [M7] [M8]
                                    â†‘
Consumer reads:  [M1] [M2] [M3] [M4]
                                    â†‘
                              Lag = 4 messages
```

**Why it matters:** High lag = consumers can't keep up

**Monitoring:**
```java
@Service
public class ConsumerLagMonitor {
    
    @Scheduled(fixedRate = 30000) // Every 30 seconds
    public void checkConsumerLag() {
        Map<TopicPartition, Long> lag = kafkaConsumer.endOffsets(partitions);
        
        lag.forEach((partition, endOffset) -> {
            long currentOffset = getCurrentOffset(partition);
            long lagCount = endOffset - currentOffset;
            
            if (lagCount > 1000) {
                logger.warn("High lag on {}: {} messages", partition, lagCount);
                alertService.sendAlert("High consumer lag detected!");
            }
        });
    }
}
```

#### 2. Throughput (Messages per Second)

**Monitoring:**
```java
@KafkaListener(topics = "order-created")
public void handleOrder(OrderCreatedEvent event) {
    // Track throughput
    meterRegistry.counter("kafka.messages.processed", 
                         "topic", "order-created").increment();
    
    processOrder(event);
}
```

#### 3. Error Rate

**Monitoring:**
```java
@KafkaListener(topics = "order-created")
public void handleOrder(OrderCreatedEvent event) {
    try {
        processOrder(event);
        meterRegistry.counter("kafka.messages.success").increment();
    } catch (Exception e) {
        meterRegistry.counter("kafka.messages.error").increment();
        throw e;
    }
}
```

#### 4. Processing Time

**Monitoring:**
```java
@KafkaListener(topics = "order-created")
public void handleOrder(OrderCreatedEvent event) {
    Timer.Sample sample = Timer.start(meterRegistry);
    
    try {
        processOrder(event);
    } finally {
        sample.stop(meterRegistry.timer("kafka.processing.time"));
    }
}
```

### Monitoring Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA MONITORING DASHBOARD              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Consumer Lag:       1,234 messages            â”‚
â”‚  Throughput:         500 msg/sec               â”‚
â”‚  Error Rate:         0.1%                      â”‚
â”‚  Avg Processing:     50ms                      â”‚
â”‚                                                 â”‚
â”‚  Topics:                                        â”‚
â”‚  â”œâ”€ order-created:   10,000 messages           â”‚
â”‚  â”œâ”€ payment-confirmed: 8,000 messages          â”‚
â”‚  â””â”€ order-created-dlq: 5 messages (âš ï¸)        â”‚
â”‚                                                 â”‚
â”‚  Partitions:                                    â”‚
â”‚  â”œâ”€ P0: Lag 400, Size 2GB                      â”‚
â”‚  â”œâ”€ P1: Lag 350, Size 1.8GB                    â”‚
â”‚  â””â”€ P2: Lag 484, Size 2.1GB                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tools for Monitoring

#### 1. Kafka Manager / CMAK

```
Features:
- View topics and partitions
- Monitor consumer groups
- Check consumer lag
- View broker status
```

#### 2. Prometheus + Grafana

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:9092']
```

#### 3. JMX Metrics

```java
// Enable JMX in application.yaml
spring:
  kafka:
    consumer:
      properties:
        spring.jmx.enabled: true
```

### Alerting Rules

```java
@Service
public class KafkaAlerts {
    
    @Scheduled(fixedRate = 60000)
    public void checkAlerts() {
        // Alert 1: High Consumer Lag
        if (consumerLag > 10000) {
            alertService.sendAlert("CRITICAL: Consumer lag > 10,000");
        }
        
        // Alert 2: High Error Rate
        double errorRate = getErrorRate();
        if (errorRate > 5.0) {
            alertService.sendAlert("CRITICAL: Error rate > 5%");
        }
        
        // Alert 3: DLQ Growing
        long dlqSize = getDLQSize();
        if (dlqSize > 100) {
            alertService.sendAlert("WARNING: DLQ has " + dlqSize + " messages");
        }
        
        // Alert 4: Low Throughput
        double throughput = getThroughput();
        if (throughput < 100) {
            alertService.sendAlert("WARNING: Throughput < 100 msg/sec");
        }
    }
}
```

### Health Checks

```java
@Component
public class KafkaHealthIndicator implements HealthIndicator {
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Override
    public Health health() {
        try {
            // Try to get metadata
            kafkaTemplate.getProducerFactory().createProducer().partitionsFor("order-created");
            
            return Health.up()
                .withDetail("kafka", "Connected")
                .build();
        } catch (Exception e) {
            return Health.down()
                .withDetail("kafka", "Disconnected")
                .withException(e)
                .build();
        }
    }
}
```

---

## Best Practices

### 1. Always Check for Duplicates (Idempotency)

```java
@KafkaListener(topics = "order-created")
public void handleOrder(OrderCreatedEvent event) {
    // Check if already processed
    if (orderRepository.existsById(event.getOrderId())) {
        return; // Skip duplicate
    }
    
    // Process order
    processOrder(event);
}
```

**Why?** Kafka might send the same event twice!

### 2. Handle Errors Gracefully

```java
@KafkaListener(topics = "order-created")
public void handleOrder(OrderCreatedEvent event) {
    try {
        processOrder(event);
    } catch (Exception e) {
        // Log error and send to dead letter queue
        logger.error("Failed to process order", e);
        kafkaTemplate.send("order-created-dlq", event);
    }
}
```

**Visual:**
```
Event arrives
    â”‚
    â–¼
Try to process
    â”‚
    â”œâ”€â†’ Success âœ… â†’ Done
    â”‚
    â””â”€â†’ Error âŒ â†’ Send to DLQ for investigation
```

### 3. Use Keys for Ordering

```java
// Same orderId always goes to same partition
kafkaTemplate.send("order-created", orderId, event);
//                           topic    key    value
```

**Why?** Maintains order for same order ID!

```
Order #123 events:
  - Created
  - Paid
  - Shipped
  
All go to same partition â†’ Processed in order âœ…
```

---

## Configuration

### application.yaml

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all  # Wait for confirmation
      
    consumer:
      group-id: my-service-group
      auto-offset-reset: earliest  # Start from beginning
```

### Simple Explanation

```
bootstrap-servers: Where is Kafka? (localhost:9092)
key-serializer: How to convert key to bytes
value-serializer: How to convert event to bytes
acks: all = Wait for confirmation (safer)
group-id: Which team am I in?
auto-offset-reset: Start from beginning if new
```

---

## Summary

### Key Takeaways

```
âœ… Events = Things that happened
âœ… Kafka = Message storage (like a mailbox)
âœ… Producers = Services that send events
âœ… Consumers = Services that react to events
âœ… Topics = Categories of events
âœ… Partitions = Allow parallel processing
âœ… Consumer Groups = Teams of workers
```

### Benefits

```
ğŸš€ Fast: Respond immediately, process later
ğŸ”Œ Loose Coupling: Services don't know each other
ğŸ“ˆ Scalable: Add more consumers = faster processing
ğŸ›¡ï¸  Fault Tolerant: If one service fails, others work
ğŸ”„ Replayable: Can replay events for debugging
```

### When to Use

```
âœ… High volume (many events)
âœ… Multiple services need to react
âœ… Need fast response times
âœ… Services should be independent
âœ… Need audit trail / event history
âœ… Need to chain events (e.g., payment â†’ processing)
```

### Important: Event Ordering

```
âš ï¸  Remember: Some events must happen in order!

Order Created â†’ Payment Confirmed â†’ Order Processing

Use event chaining to ensure proper order!
```

---

## Quick Reference

### Publishing Event
```java
kafkaTemplate.send("topic-name", key, event);
```

### Consuming Event
```java
@KafkaListener(topics = "topic-name", groupId = "my-group")
public void handle(Event event) {
    // Process event
}
```

### Key Concepts
- **Topic** = Category (e.g., "order-created")
- **Partition** = Sub-category for parallel processing
- **Consumer Group** = Team of workers (same service instances)
- **Key** = Ensures same key goes to same partition
- **Group ID** = Must be same for all instances of same service

### Multiple Instances Rules

```
âœ… Same groupId = Same team (work together, no duplicates)
âœ… One partition = One consumer (in same group)
âœ… Kafka automatically assigns partitions
âœ… If instance dies, Kafka reassigns partition to another instance
âœ… Different services = Different groupIds (all get events)
```

---

## Next Steps

1. âœ… Understand the basics (you're here!)
2. ğŸ“ Implement producer in your service
3. ğŸ“ Implement consumer in your service
4. ğŸ§ª Test with local Kafka
5. ğŸ“Š Monitor and optimize

---

**Remember:** Event-driven architecture is like a newspaper - publishers don't wait for readers, they just publish and move on! ğŸ“°
